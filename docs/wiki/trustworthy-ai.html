<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Trustworthy AI | VSAVM</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Fraunces:wght@400;600&family=Space+Grotesk:wght@400;500;600&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="../assets/site.css">
  </head>
  <body>
    <div class="site">
      <header class="header">
        <div class="brand">VSAVM</div>
        <nav class="nav">
          <a href="../index.html">Home</a>
          <a href="../specs/">Specs</a>
          <a href="../theory/index.html">Theory</a>
          <a href="../wiki/index.html">Wiki</a>
        </nav>
      </header>
      <main class="main content">
        <h1>Trustworthy AI</h1>
<p>This wiki entry defines a term used across VSAVM and explains why it matters in the architecture.</p><p>The diagram has a transparent background and highlights the operational meaning of the term inside VSAVM.</p>
<p>Related wiki pages: <a href="vm.html">VM</a>, <a href="event-stream.html">event stream</a>, <a href="vsa.html">VSA</a>, <a href="bounded-closure.html">bounded closure</a>, <a href="consistency-contract.html">consistency contract</a>.</p>
<h2>Definition</h2>
<p>Trustworthy AI refers to systems that behave predictably and transparently, especially at the boundaries of uncertainty.</p>
<h2>Role in VSAVM</h2>
<p>VSAVM approaches trustworthiness by construction: it constrains emission to what can be derived and checked under bounded closure and exposes traces and budgets on demand.</p>
<h2>Mechanics and implications</h2>
<p>The system’s outputs are classified into robust, conditional, or indeterminate based on closure and scope. This replaces ungrounded confidence with operational coverage. The surface realizer is constrained to avoid introducing facts beyond VM state.</p>
<h2>Further reading</h2>
<p>Trustworthy AI intersects with explainability, verification, and alignment. VSAVM’s contribution is to provide an executable substrate that makes these concerns operational and auditable.</p>
<figure class="diagram">
<img class="diagram-svg" src="../assets/svg/trustworthy-ai-diagram.svg" alt="trustworthy-ai diagram">
<figcaption>Trust is built by tying outputs to traces and checks and by using explicit output modes.</figcaption>
</figure>
<h2>References</h2>
<p><a href="https://en.wikipedia.org/wiki/Explainable_artificial_intelligence">Explainable AI (Wikipedia)</a> <a href="https://en.wikipedia.org/wiki/Verification_and_validation">Verification and validation (Wikipedia)</a> <a href="https://en.wikipedia.org/wiki/AI_alignment">AI alignment (Wikipedia)</a></p>
      </main>
      <footer class="footer">
        VSAVM is an Axiologic Research experiment within the Achilles project. This static documentation is written in clear academic English for engineers.
      </footer>
    </div>
  </body>
</html>
