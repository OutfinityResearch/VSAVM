<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Large Language Model (LLM) | VSAVM</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Fraunces:wght@400;600&family=Space+Grotesk:wght@400;500;600&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="../assets/site.css">
  </head>
  <body>
    <div class="site">
      <header class="header">
        <div class="brand">VSAVM</div>
        <nav class="nav">
          <a href="../index.html">Home</a>
          <a href="../specs/">Specs</a>
          <a href="../theory/index.html">Theory</a>
          <a href="../wiki/index.html">Wiki</a>
        </nav>
      </header>
      <main class="main content">
        <h1>Large Language Model (LLM)</h1>
<p>This wiki entry defines a term used across VSAVM and explains why it matters in the architecture.</p><p>The diagram has a transparent background and highlights the operational meaning of the term inside VSAVM.</p>
<p>Related wiki pages: <a href="vm.html">VM</a>, <a href="event-stream.html">event stream</a>, <a href="vsa.html">VSA</a>, <a href="bounded-closure.html">bounded closure</a>, <a href="consistency-contract.html">consistency contract</a>.</p>
<h2>Definition</h2>
<p>A large language model is typically a neural network trained to predict the next token or segment of text.</p>
<h2>Role in VSAVM</h2>
<p>VSAVM uses LLM-like prediction as a proposal mechanism, but acceptance is constrained by VM state and bounded closure. The interface stays familiar while the semantics change.</p>
<h2>Mechanics and implications</h2>
<p>Fluency proposals are filtered by schema constraints and closure gating. This prevents the generator from emitting facts that are not supported by executable state, turning trust into an operational property of checks and traces.</p>
<h2>Further reading</h2>
<p>LLMs are a fast-moving field. VSAVMâ€™s design goal is to combine LLM-like interaction with an executable substrate and explicit boundary behavior.</p>
<figure class="diagram">
<img class="diagram-svg" src="../assets/svg/llm-diagram.svg" alt="llm diagram">
<figcaption>VSAVM keeps LLM-like interaction but conditions continuations on executable state and closure checks.</figcaption>
</figure>
<h2>References</h2>
<p><a href="https://en.wikipedia.org/wiki/Large_language_model">Large language model (Wikipedia)</a> <a href="https://en.wikipedia.org/wiki/Language_model">Language model (Wikipedia)</a> <a href="https://en.wikipedia.org/wiki/Natural_language_generation">Natural language generation (Wikipedia)</a></p>
      </main>
      <footer class="footer">
        VSAVM is an Axiologic Research experiment within the Achilles project. This static documentation is written in clear academic English for engineers.
      </footer>
    </div>
  </body>
</html>
