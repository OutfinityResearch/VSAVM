<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Large Language Model (LLM) | VSAVM</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Fraunces:wght@400;600&family=Space+Grotesk:wght@400;500;600&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="../assets/site.css">
  </head>
  <body>
    <div class="site">
      <header class="header">
        <div class="brand">VSAVM</div>
        <nav class="nav">
          <a href="../index.html">Home</a>
          <a href="../specs/">Specs</a>
          <a href="../theory/index.html">Theory</a>
          <a href="../wiki/index.html">Wiki</a>
        </nav>
      </header>
      <main class="main content">
        <h1>Large Language Model (LLM)</h1>
<p>This wiki entry defines a term used across VSAVM and explains why it matters in the architecture.</p><p>The diagram has a transparent background and highlights the operational meaning of the term inside VSAVM.</p>
<p>Related wiki pages: <a href="vm.html">VM</a>, <a href="event-stream.html">event stream</a>, <a href="vsa.html">VSA</a>, <a href="bounded-closure.html">bounded closure</a>, <a href="consistency-contract.html">consistency contract</a>.</p>
<h2>Definition</h2>
<p>A large language model is typically a neural network trained to predict the next token (or next segment) of text. In VSAVM, “LLM-like” describes the <em>interface</em> (interactive continuation), not the source of truth.</p>
<h2>Role in VSAVM</h2>
<p>VSAVM uses continuation prediction as a proposal mechanism, but correctness is owned by the VM and bounded closure:</p>
<ul>
  <li><strong>Proposals</strong>: continuations can come from a neural model (baseline) or from VSAVM’s own macro-unit model (DS011).</li>
  <li><strong>Acceptance</strong>: factual claims are only emitted when supported by executable state and the correctness contract (DS004).</li>
  <li><strong>Boundary behavior</strong>: when budgets are insufficient, outputs must degrade to conditional or indeterminate instead of “guessing”.</li>
</ul>
<h2>Mechanics and implications</h2>
<p>In this repository, two “LLM-like” paths exist:</p>
<ul>
  <li><strong>Query answering (default)</strong>: execute a query in the VM, run bounded closure, then render checked claims deterministically.</li>
  <li><strong>Continuation (DS011, evaluation harness)</strong>: train a macro-unit language model to continue byte sequences under budgets. This is compared against a small TensorFlow Transformer baseline in <code>eval_tinyLLM</code>.</li>
</ul>
<p>The important implication is that fluency is never treated as truth. Continuation quality is measured as a language-model metric (perplexity, reference match, repetition), while correctness for claims is measured via VM/closure.</p>

<h2>Practical evaluation (eval_tinyLLM)</h2>
<p>The <code>eval_tinyLLM</code> suite exists to make “more realistic” comparisons reproducible while keeping the codebase dependency-light:</p>
<ol>
  <li><strong>Prepare a dataset split</strong> under a deterministic <code>datasetId</code> (size-based, keyed by <code>maxBytes</code> and split settings).</li>
  <li><strong>Train VSAVM macro-units</strong> (streaming) and optionally persist facts.</li>
  <li><strong>Train the TensorFlow baseline</strong> on the same dataset.</li>
  <li><strong>Compare</strong> both engines under identical budgets per prompt and write a timestamped HTML report to <code>eval_tinyLLM/results/</code>.</li>
</ol>
<p>Artifacts are cached under <code>eval_tinyLLM/cache/datasets/</code> and <code>eval_tinyLLM/cache/models/</code> so multiple dataset sizes and multiple trained models can coexist.</p>
<h2>Further reading</h2>
<p>LLMs are a fast-moving field. VSAVM’s design goal is to combine LLM-like interaction with an executable substrate and explicit boundary behavior.</p>
<figure class="diagram">
<img class="diagram-svg" src="../assets/svg/llm-diagram.svg" alt="llm diagram">
<figcaption>VSAVM keeps LLM-like interaction but conditions continuations on executable state and closure checks.</figcaption>
</figure>
<h2>References</h2>
<p><a href="https://en.wikipedia.org/wiki/Large_language_model">Large language model (Wikipedia)</a> <a href="https://en.wikipedia.org/wiki/Language_model">Language model (Wikipedia)</a> <a href="https://en.wikipedia.org/wiki/Natural_language_generation">Natural language generation (Wikipedia)</a></p>
      </main>
      <footer class="footer">
        VSAVM is an Axiologic Research experiment within the Achilles project. This static documentation is written in clear academic English for engineers.
      </footer>
    </div>
  </body>
</html>
