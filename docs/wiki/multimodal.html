<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Multimodal | VSAVM</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Fraunces:wght@400;600&family=Space+Grotesk:wght@400;500;600&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="../assets/site.css">
  </head>
  <body>
    <div class="site">
      <header class="header">
        <div class="brand">VSAVM</div>
        <nav class="nav">
          <a href="../index.html">Home</a>
          <a href="../specs/">Specs</a>
          <a href="../theory/index.html">Theory</a>
          <a href="../wiki/index.html">Wiki</a>
        </nav>
      </header>
      <main class="main content">
        <h1>Multimodal</h1>
<p>This wiki entry defines a term used across VSAVM and explains why it matters in the architecture.</p><p>The diagram has a transparent background and highlights the operational meaning of the term inside VSAVM.</p>
<p>Related wiki pages: <a href="vm.html">VM</a>, <a href="event-stream.html">event stream</a>, <a href="vsa.html">VSA</a>, <a href="bounded-closure.html">bounded closure</a>, <a href="consistency-contract.html">consistency contract</a>.</p>
<h2>Definition</h2>
<p>Multimodal processing integrates multiple input or output modalities such as text, audio, and images.</p>
<h2>Role in VSAVM</h2>
<p>VSAVM is multimodal by representation: all modalities become event streams. This allows one VM and one correctness contract to operate uniformly across modalities.</p>
<h2>Mechanics and implications</h2>
<p>Audio becomes transcript events with timing; images and video become symbolic descriptors or discrete tokens. Structural separators define scope even in temporal streams. The VM remains modality-agnostic because it consumes discrete events and canonical facts.</p>
<h2>Further reading</h2>
<p>Multimodal learning literature is broad. VSAVMâ€™s emphasis is on representation unification and execution-based checking, not on any specific encoder design.</p>
<figure class="diagram">
<img class="diagram-svg" src="../assets/svg/multimodal-diagram.svg" alt="multimodal diagram">
<figcaption>Multiple modalities converge into a single event stream so the same closure rules apply.</figcaption>
</figure>
<h2>References</h2>
<p><a href="https://en.wikipedia.org/wiki/Multimodal_learning">Multimodal learning (Wikipedia)</a> <a href="https://en.wikipedia.org/wiki/Event_stream_processing">Event stream processing (Wikipedia)</a> <a href="https://en.wikipedia.org/wiki/Computer_vision">Computer vision (Wikipedia)</a></p>
      </main>
      <footer class="footer">
        VSAVM is an Axiologic Research experiment within the Achilles project. This static documentation is written in clear academic English for engineers.
      </footer>
    </div>
  </body>
</html>
