<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Trust and transparency | VSAVM</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Fraunces:wght@400;600&family=Space+Grotesk:wght@400;500;600&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="../assets/site.css">
  </head>
  <body>
    <div class="site">
      <header class="header">
        <div class="brand">VSAVM</div>
        <nav class="nav">
          <a href="../index.html">Home</a>
          <a href="../specs/">Specs</a>
          <a href="../theory/index.html">Theory</a>
          <a href="../wiki/index.html">Wiki</a>
        </nav>
      </header>
      <main class="main content">
        <h1>Trust and transparency</h1>
<p>This page is a theory note. It expands the topic in short chapters and defines terminology without duplicating the formal specification documents.</p><p>The diagram has a transparent background and is intended to be read together with the caption and the sections below.</p>
<p>Related wiki pages: <a href="../wiki/vm.html">VM</a>, <a href="../wiki/event-stream.html">event stream</a>, <a href="../wiki/vsa.html">VSA</a>, <a href="../wiki/bounded-closure.html">bounded closure</a>, <a href="../wiki/consistency-contract.html">consistency contract</a>.</p>
<p>Related specs: <a href="../specs-viewer.html?doc=specs/DS004-correctness-bounded-closure.md">DS004</a>.</p>
<h2>Overview</h2>
<p>Trustworthy behavior is achieved by changing what the system is allowed to emit. VSAVM does not aim to be cautious by tone; it aims to be constrained by computation. If a claim cannot be justified under closure, it must not be stated as robust.</p>
<h2>Reducing hallucinations</h2>
<p>Hallucinations are often failures of emission discipline. VSAVM prevents this by requiring that factual sentences correspond to canonical facts or explicit derivations. The surface realizer can explain what happened, but it cannot introduce new claims beyond VM state and trace.</p>
<h2>Explainability as audit</h2>
<p>Explanations are operational. The system can report the budget used, the number of explored branches, the rules applied, and any conflicts detected. This avoids post-hoc narratives that sound plausible but are not connected to the actual computation.</p>
<h2>Limits and honest uncertainty</h2>
<p>Bounded closure is incomplete by design. The promise is not absolute truth; it is honesty about what was checked. When budget is insufficient, VSAVM degrades to conditional or indeterminate outputs and can suggest increasing budget if the user wants stronger guarantees.</p>
<figure class="diagram">
<img class="diagram-svg" src="../assets/svg/trust-and-transparency-diagram.svg" alt="trust-and-transparency diagram">
<figcaption>Trust is earned by tying outputs to traces and checks and by disclosing budget and mode rather than projecting confidence.</figcaption>
</figure>
<h2>References</h2>
<p><a href="https://en.wikipedia.org/wiki/Explainable_artificial_intelligence">Explainable AI (Wikipedia)</a> <a href="https://en.wikipedia.org/wiki/Verification_and_validation">Verification and validation (Wikipedia)</a> <a href="https://en.wikipedia.org/wiki/AI_alignment">AI alignment (Wikipedia)</a></p>
      </main>
      <footer class="footer">
        VSAVM is an Axiologic Research experiment within the Achilles project. This static documentation is written in clear academic English for engineers.
      </footer>
    </div>
  </body>
</html>
