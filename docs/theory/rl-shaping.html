<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>RL as shaping for stable choices | VSAVM</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Fraunces:wght@400;600&family=Space+Grotesk:wght@400;500;600&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="../assets/site.css">
  </head>
  <body>
    <div class="site">
      <header class="header">
        <div class="brand">VSAVM</div>
        <nav class="nav">
          <a href="../index.html">Home</a>
          <a href="../specs/">Specs</a>
          <a href="../theory/index.html">Theory</a>
          <a href="../wiki/index.html">Wiki</a>
        </nav>
      </header>
      <main class="main content">
        <h1>RL as shaping for stable choices</h1>
<p>This page is a theory note. It expands the topic in short chapters and defines terminology without duplicating the formal specification documents.</p><p>The diagram has a transparent background and is intended to be read together with the caption and the sections below.</p>
<p>Related wiki pages: <a href="../wiki/vm.html">VM</a>, <a href="../wiki/event-stream.html">event stream</a>, <a href="../wiki/vsa.html">VSA</a>, <a href="../wiki/bounded-closure.html">bounded closure</a>, <a href="../wiki/consistency-contract.html">consistency contract</a>.</p>
<p>Related specs: <a href="../specs-viewer.html?doc=specs/DS005-training-learning-optimization.md">DS005</a>.</p>
<h2>Overview</h2>
<p>VSAVM uses RL as shaping rather than as a replacement for language training. The system often faces multiple plausible candidate programs or response modes. A learned preference can bias selection toward candidates that have historically remained consistent under closure.</p>
<h2>What is optimized</h2>
<p>The action space is intentionally small: selecting among candidate programs, schemas, or response modes. This avoids token-level RL, which is expensive and difficult to audit. Each action corresponds to a semantic decision that can be logged and evaluated.</p>
<h2>Signals and discipline</h2>
<p>Bounded closure naturally provides negative feedback when contradictions are detected. Additional shaping can penalize branching blow-ups and reward compact programs. The resulting preferences steer search toward stable solutions without overriding the explicit consistency gate.</p>
<h2>Trade-offs</h2>
<p>Shaping can overfit to a narrow verifier if the verifier does not reflect the real failure modes. The safe approach is to keep RL as a stability prior while maintaining the correctness guarantee in explicit closure checks and deterministic boundary behavior.</p>
<figure class="diagram">
<svg viewBox="0 0 800 240" role="img" aria-label="RL shaping diagram">
  <defs>
    <linearGradient id="sky" x1="0" y1="0" x2="1" y2="1">
      <stop offset="0" stop-color="#e8f3ff"/>
      <stop offset="1" stop-color="#d6f5e8"/>
    </linearGradient>
    <linearGradient id="deep" x1="0" y1="0" x2="1" y2="1">
      <stop offset="0" stop-color="#0b6eff"/>
      <stop offset="1" stop-color="#16b879"/>
    </linearGradient>
  </defs>
  <rect x="50" y="40" rx="12" ry="12" width="200" height="60" fill="url(#sky)" stroke="#7fb3e6" stroke-width="2"/>
  <text x="150" y="75" text-anchor="middle" font-size="13" fill="#0b1a2b" font-family="Space Grotesk">Candidates</text>
  <line x1="250" y="70" x2="290" y2="70" stroke="url(#deep)" stroke-width="3" stroke-linecap="round"/>
  <polygon points="280,65 280,75 290,70" fill="#16b879"/>
  <rect x="290" y="40" rx="12" ry="12" width="200" height="60" fill="url(#sky)" stroke="#7fb3e6" stroke-width="2"/>
  <text x="390" y="75" text-anchor="middle" font-size="13" fill="#0b1a2b" font-family="Space Grotesk">Consistency Signals</text>
  <line x1="490" y1="70" x2="530" y2="70" stroke="url(#deep)" stroke-width="3" stroke-linecap="round"/>
  <polygon points="520,65 520,75 530,70" fill="#16b879"/>
  <rect x="530" y="40" rx="12" ry="12" width="200" height="60" fill="url(#sky)" stroke="#7fb3e6" stroke-width="2"/>
  <text x="630" y="75" text-anchor="middle" font-size="13" fill="#0b1a2b" font-family="Space Grotesk">Selection Policy</text>
  <rect x="150" y="130" rx="12" ry="12" width="480" height="50" fill="url(#sky)" stroke="#7fb3e6" stroke-width="2"/>
  <text x="390" y="160" text-anchor="middle" font-size="13" fill="#0b1a2b" font-family="Space Grotesk">Penalty when closure reveals in-scope contradictions</text>
  <line x1="390" y1="100" x2="390" y2="130" stroke="#0b6eff" stroke-width="3" stroke-linecap="round"/>
  <polygon points="385,120 395,120 390,130" fill="#0b6eff"/>
  <text x="65" y="210" text-anchor="start" font-size="11" fill="#2f4a63" font-family="Space Grotesk">RL shapes selection, but consistency provides the signal.</text>
</svg>
<figcaption>RL provides shaping signals for discrete choices, prioritizing candidates that remain stable under bounded closure.</figcaption>
</figure>
<h2>References</h2>
<p><a href="https://en.wikipedia.org/wiki/Reinforcement_learning">Reinforcement learning (Wikipedia)</a> <a href="http://incompleteideas.net/book/the-book-2nd.html">Sutton & Barto (book)</a> <a href="https://en.wikipedia.org/wiki/Multi-armed_bandit">Multi-armed bandit (Wikipedia)</a></p>
      </main>
      <footer class="footer">
        VSAVM is an Axiologic Research experiment within the Achilles project. This static documentation is written in clear academic English for engineers.
      </footer>
    </div>
  </body>
</html>
