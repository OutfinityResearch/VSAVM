<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Training and emergent compilation | VSAVM</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Fraunces:wght@400;600&family=Space+Grotesk:wght@400;500;600&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="../assets/site.css">
  </head>
  <body>
    <div class="site">
      <header class="header">
        <div class="brand">VSAVM</div>
        <nav class="nav">
          <a href="../index.html">Home</a>
          <a href="../specs/">Specs</a>
          <a href="../theory/index.html">Theory</a>
          <a href="../wiki/index.html">Wiki</a>
        </nav>
      </header>
      <main class="main content">
        <h1>Training and emergent compilation</h1>
<p>This page is a theory note. It expands the topic in short chapters and defines terminology without duplicating the formal specification documents.</p><p>The diagram has a transparent background and is intended to be read together with the caption and the sections below.</p>
<p>Related wiki pages: <a href="../wiki/vm.html">VM</a>, <a href="../wiki/event-stream.html">event stream</a>, <a href="../wiki/vsa.html">VSA</a>, <a href="../wiki/bounded-closure.html">bounded closure</a>, <a href="../wiki/consistency-contract.html">consistency contract</a>, <a href="../wiki/mdl.html">MDL</a>, <a href="../wiki/rl.html">RL</a>.</p>
<p>Related specs: <a href="../specs-viewer.html?doc=specs/DS005-training-learning-optimization.md">DS005</a>.</p>

<h2>Overview</h2>
<p>VSAVM treats compilation as a learned capability. Next-phrase prediction provides a broad surface prior, but repeated patterns create pressure to represent intent as executable programs that compress the data. This creates a path from language modeling to program induction without hardcoded templates.</p>

<h2>Two-loop training architecture</h2>
<p>The training process operates through a sophisticated dual-loop architecture:</p>
<ul>
  <li><strong>Outer loop (next-phrase prediction)</strong>: Extends traditional language modeling with conditioning on virtual machine state. Predictions incorporate active facts, applicable rules, and ongoing reasoning processes. Phrase-level prediction (not token-level) creates more meaningful semantic units that map directly to symbolic operations, reducing computational overhead.</li>
  <li><strong>Inner loop (program search and consolidation)</strong>: Continuously proposes and tests candidate programs that might explain observed patterns. Operates in parallel with language modeling, focusing on underlying logical structure. Uses beam search with primitive operations, transformation rules, and existing program adaptation.</li>
  <li><strong>Loop synchronization</strong>: The language modeling loop provides feedback about which reasoning leads to more predictable text. The program search loop identifies linguistic patterns associated with successful strategies. Shared representations enable information flow between loops while preventing interference.</li>
</ul>

<h2>What emerges and why</h2>
<p>Repeated question forms and reasoning moves become schemas and macro programs because they reduce description length. VSA accelerates the emergence by clustering paraphrases and providing fast retrieval of nearby patterns. The VM provides the semantics by executing candidates and maintaining explicit state.</p>
<p>Training data preparation segments the corpus into logical units (arguments, explanations, Q&A pairs) that support both language modeling and program induction. Different content types receive different treatment: factual content for knowledge representation, argumentative content for logical reasoning, procedural content for step-by-step problem solving.</p>

<h2>Compression-driven learning</h2>
<p>The learning process operates under MDL (Minimum Description Length) guidance:</p>
<ul>
  <li><strong>MDL criterion</strong>: Favors compact representations explaining large amounts of training data. Considers both individual component complexity and interaction complexity. Prevents overfitting while encouraging discovery of broadly applicable patterns.</li>
  <li><strong>Multi-level pattern recognition</strong>:
    <ul>
      <li>Surface-level: recurring phrases, sentence structures, discourse patterns for fluency</li>
      <li>Intermediate-level: recurring reasoning strategies and problem-solving approaches for transfer</li>
      <li>Deep-level: fundamental logical structures underlying many surface manifestations</li>
    </ul>
  </li>
  <li><strong>Schema emergence</strong>: Bottom-up discovery identifies statistical regularities; top-down testing evaluates compression benefits and generalization. Rigorous validation on held-out data prevents spurious schemas.</li>
  <li><strong>Consolidation decisions</strong>: Conservative criteria require substantial evidence before creating/modifying schemas. Consider frequency, consistency of effectiveness, and generalizability. Include mechanisms for merging similar schemas and eliminating redundancy.</li>
</ul>

<h2>Consolidation</h2>
<p>Consolidation is the point where a candidate program becomes a macro instruction. It improves performance, but it also improves stability because the system can treat the macro as a unit that can be tested, audited, versioned, and federated. Consolidation is therefore an engineering mechanism, not only a learning trick.</p>

<h2>Reinforcement learning integration</h2>
<p>RL provides targeted optimization for specific reasoning aspects while preserving the statistical foundation:</p>
<ul>
  <li><strong>Hypothesis selection rewards</strong>: Guide toward reasoning approaches likely to produce correct, consistent results. Multi-faceted rewards consider accuracy, consistency, efficiency, and robustness. Reward shaping provides intermediate rewards for promising steps.</li>
  <li><strong>Consistency discipline penalties</strong>: Discourage approaches leading to contradictions. Consider both direct and indirect contradictions (via bounded closure). Calibrated severity avoids overwhelming the learning process while maintaining rigor.</li>
  <li><strong>Bandit and offline preference methods</strong>: Computationally efficient alternatives to policy gradient methods. Multi-armed bandits for strategy selection with exploration-exploitation balance. Contextual bandits incorporate reasoning context. Offline preference learning uses human feedback without online interaction.</li>
  <li><strong>Integration safeguards</strong>: RL enhances rather than replaces statistical learning. Operates primarily on high-level reasoning decisions, leaving low-level language generation to statistical components. Prevents local optima that sacrifice long-term learning.</li>
</ul>

<h2>Performance optimization and scaling</h2>
<p>Performance optimization ensures efficient operation with large knowledge bases:</p>
<ul>
  <li><strong>VSA acceleration</strong>: Leverage parallel/associative hypervector operations via SIMD, GPU, or neuromorphic hardware. Caching for frequently used hypervectors. Approximate similarity search with indexing and pruning.</li>
  <li><strong>VM execution optimization</strong>: Instruction-level optimization (operation fusion, redundant computation elimination). Program-level optimization (operation reordering, parallelism exploitation). Just-in-time compilation for frequently executed programs.</li>
  <li><strong>Memory management</strong>: Hierarchical caching with learned access patterns. Garbage collection that respects logical structure. Incremental consistency checking focused on modified portions.</li>
  <li><strong>Distributed execution</strong>: Partitioning strategies balancing communication overhead and load balance. Consistency protocols for distributed reasoning. Fault tolerance mechanisms (reactive and proactive). Load balancing across computing resources.</li>
</ul>

<h2>Risks and mitigations</h2>
<p>Compression can consolidate spurious patterns if prediction alone is the criterion. VSAVM mitigates this by using bounded closure as a validator and by using scope to prevent unstable rules from contaminating unrelated contexts. Rules that cause branching blow-ups or frequent contradictions should be demoted or isolated.</p>
<figure class="diagram">
<img class="diagram-svg" src="../assets/svg/training-and-emergence-diagram.svg" alt="training-and-emergence diagram">
<figcaption>Compilation emerges when prediction pressure makes compact executable programs the cheapest explanation for recurring patterns. RL shaping and consolidation work together to stabilize learned reasoning.</figcaption>
</figure>
<h2>References</h2>
<p><a href="https://en.wikipedia.org/wiki/Minimum_description_length">Minimum description length (Wikipedia)</a> <a href="https://www.grunwald.nl/mdlbook/">The MDL Book (Grunwald)</a> <a href="https://en.wikipedia.org/wiki/Program_synthesis">Program synthesis (Wikipedia)</a> <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">Reinforcement learning (Wikipedia)</a></p>
      </main>
      <footer class="footer">
        VSAVM is an Axiologic Research experiment within the Achilles project. This static documentation is written in clear academic English for engineers.
      </footer>
    </div>
  </body>
</html>
